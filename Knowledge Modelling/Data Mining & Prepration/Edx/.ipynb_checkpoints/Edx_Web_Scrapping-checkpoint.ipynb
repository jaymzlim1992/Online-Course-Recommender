{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKP_hXCOvsq0"
   },
   "source": [
    "# Online Course Recommender\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Practice Module: Intelligent Reasoning Systems (IRS)\n",
    "\n",
    "## Data Mining: Web Scrapping Edx.org\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idUoUyrtwkWW"
   },
   "source": [
    "## 0. Preparation & Mounting Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_aZ9kOgBp3l",
    "outputId": "5f3b43aa-2abf-4b6a-dba3-51d9c6df815f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]    \u001b[0m\u001b[33m\n",
      "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,430 kB]\n",
      "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,800 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,208 kB]\n",
      "Fetched 6,695 kB in 3s (2,388 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "37 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
      "Suggested packages:\n",
      "  webaccounts-chromium-extension unity-chromium-extension\n",
      "The following NEW packages will be installed:\n",
      "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
      "  chromium-codecs-ffmpeg-extra\n",
      "0 upgraded, 4 newly installed, 0 to remove and 37 not upgraded.\n",
      "Need to get 92.6 MB of archives.\n",
      "After this operation, 317 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 93.0.4577.63-0ubuntu0.18.04.1 [1,135 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 93.0.4577.63-0ubuntu0.18.04.1 [82.4 MB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 93.0.4577.63-0ubuntu0.18.04.1 [4,133 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 93.0.4577.63-0ubuntu0.18.04.1 [4,961 kB]\n",
      "Fetched 92.6 MB in 3s (27.6 MB/s)\n",
      "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
      "(Reading database ... 155047 files and directories currently installed.)\n",
      "Preparing to unpack .../chromium-codecs-ffmpeg-extra_93.0.4577.63-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-codecs-ffmpeg-extra (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-browser.\n",
      "Preparing to unpack .../chromium-browser_93.0.4577.63-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-browser (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-browser-l10n.\n",
      "Preparing to unpack .../chromium-browser-l10n_93.0.4577.63-0ubuntu0.18.04.1_all.deb ...\n",
      "Unpacking chromium-browser-l10n (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-chromedriver.\n",
      "Preparing to unpack .../chromium-chromedriver_93.0.4577.63-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-chromedriver (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-codecs-ffmpeg-extra (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-browser (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
      "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
      "Setting up chromium-chromedriver (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-browser-l10n (93.0.4577.63-0ubuntu0.18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Collecting selenium\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "\u001b[K     |████████████████████████████████| 904 kB 39.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install chromium-chromedriver\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MtbQU2DOvp1T"
   },
   "outputs": [],
   "source": [
    "# Load All Necessary Packages\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set options to be headless, ..\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0dVjxhrvofj",
    "outputId": "21350977-141f-45a6-d908-a737af0f3eea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mounting to Google Drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Change Working Directory\n",
    "os.chdir('/content/gdrive/My Drive/iss/irs_pm/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpi2cqXwy8tO"
   },
   "source": [
    "## 1. Load and Request the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ekg8wAO6zCHK"
   },
   "outputs": [],
   "source": [
    "# open it, go to a website, and get results\n",
    "\n",
    "edx_course_url = 'https://www.edx.org/search?tab=course#main-content'\n",
    "edx_program_url = 'https://www.edx.org/search?tab=program#main-content'\n",
    "\n",
    "# Initialize chrome driver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "wd = webdriver.Chrome('chromedriver',options=options)\n",
    "wd.implicitly_wait(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6iUNPrzjcsb"
   },
   "outputs": [],
   "source": [
    "# wd.delete_all_cookies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfF8WyztvNjt"
   },
   "outputs": [],
   "source": [
    "# Custom function for progress loading status update\n",
    "\n",
    "def loading_status_update_list(tot_count, cat_count, update_freq):\n",
    "  if (tot_count % update_freq) == 0:\n",
    "    print('Finishing scrapping', end='')\n",
    "    print('.....', end='')\n",
    "    print('.....', end='')\n",
    "    print(f'Total of {tot_count} courses extracted..... ', end='')\n",
    "    print(f'Total of {cat_count} catagories extracted.....')\n",
    "  return 0\n",
    "\n",
    "\n",
    "def loading_status_update_course(num_course, update_freq):\n",
    "  if (num_course % update_freq) == 0:\n",
    "    print('Finishing scrapping', end='')\n",
    "    print('.....', end='')\n",
    "    print('.....', end='')\n",
    "    print(f'Total of {num_course} course.', end='')\n",
    "  return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNblxCyubsZq"
   },
   "outputs": [],
   "source": [
    "# Custom function to check if a html element exists\n",
    "\n",
    "def check_element_exist(xpath):\n",
    "  try:\n",
    "    wd.find_element_by_xpath(\"//button[@class='btn next page-link']\")\n",
    "  except NoSuchElementException:\n",
    "    return False\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHpUpVZPA-B3",
    "outputId": "c3c8edae-05f2-4586-c67d-36363c7dd152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# Get Course Categories\n",
    "\n",
    "wd.get(edx_course_url)\n",
    "time.sleep(2)\n",
    "category_list = []\n",
    "\n",
    "course_mainpage = BeautifulSoup(wd.page_source, 'html.parser')\n",
    "categories = course_mainpage.find_all(id=re.compile('subject-'))\n",
    "for cat in categories:\n",
    "  category_list.append(cat['value'])\n",
    "\n",
    "print(len(category_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkEJjd7-MjFl",
    "outputId": "f0083b49-1e3e-4a15-964e-8a4f68cbbf27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finishing scrapping..........Total of 500 courses extracted..... Total of 4 catagories extracted.....\n",
      "Finishing scrapping..........Total of 1000 courses extracted..... Total of 4 catagories extracted.....\n",
      "Finishing scrapping..........Total of 1500 courses extracted..... Total of 6 catagories extracted.....\n",
      "Finishing scrapping..........Total of 2000 courses extracted..... Total of 7 catagories extracted.....\n",
      "Finishing scrapping..........Total of 2500 courses extracted..... Total of 8 catagories extracted.....\n",
      "Finishing scrapping..........Total of 3000 courses extracted..... Total of 10 catagories extracted.....\n",
      "Finishing scrapping..........Total of 3500 courses extracted..... Total of 14 catagories extracted.....\n",
      "Finishing scrapping..........Total of 4000 courses extracted..... Total of 14 catagories extracted.....\n",
      "Finishing scrapping..........Total of 4500 courses extracted..... Total of 18 catagories extracted.....\n",
      "Finishing scrapping..........Total of 5000 courses extracted..... Total of 20 catagories extracted.....\n",
      "Finishing scrapping..........Total of 5500 courses extracted..... Total of 24 catagories extracted.....\n",
      "Finishing scrapping..........Total of 6000 courses extracted..... Total of 29 catagories extracted.....\n",
      "Finishing scrapping..........Total of 6500 courses extracted..... Total of 31 catagories extracted.....\n",
      "Scrapping course list completed! Total of 6893 courses extracted.\n"
     ]
    }
   ],
   "source": [
    "# Get all course names, provider and url from each category\n",
    "\n",
    "domain_url = 'https://www.edx.org'\n",
    "pg_button_xpath = \"//button[@class='btn next page-link']\"\n",
    "\n",
    "course_name = []\n",
    "course_category = []\n",
    "course_provider = []\n",
    "course_url = []\n",
    "num_course = 0\n",
    "num_cat = 0\n",
    "\n",
    "for cat in category_list:\n",
    "  cat_course_url = f\"https://www.edx.org/search?subject={cat.replace(' & ', '%20%26%20')}&tab=course\"\n",
    "  wd.get(cat_course_url)\n",
    "  num_cat += 1\n",
    "  if check_element_exist(pg_button_xpath):\n",
    "    next_pg_button = wd.find_element_by_xpath(pg_button_xpath)\n",
    "    # Loop through all pages of course list\n",
    "    while next_pg_button.is_enabled():\n",
    "      bs = BeautifulSoup(wd.page_source, 'html.parser')\n",
    "      course_on_page = bs.find_all('div', class_='discovery-card col')\n",
    "      for course in course_on_page:\n",
    "        name = course['aria-label']\n",
    "        if course.find('img', class_='partner-logo') is not None:\n",
    "          provider = course.find('img', class_='partner-logo')['alt']\n",
    "        else:\n",
    "          provider = ''\n",
    "        url_untrim = course.a['href']\n",
    "        url = domain_url + url_untrim[:url_untrim.find('?index=product')]\n",
    "        course_name.append(name)\n",
    "        course_category.append(cat)\n",
    "        course_provider.append(provider)\n",
    "        course_url.append(url)\n",
    "        num_course += 1\n",
    "        loading_status_update_list(num_course, num_cat, 500)\n",
    "      next_pg_button.click()\n",
    "      time.sleep(1)\n",
    "\n",
    "  # To extract course information on last page of course list\n",
    "  bs = BeautifulSoup(wd.page_source, 'html.parser')\n",
    "  course_on_page = bs.find_all('div', class_='discovery-card col')\n",
    "  for course in course_on_page:\n",
    "    name = course['aria-label']\n",
    "    if course.find('img', class_='partner-logo') is not None:\n",
    "      provider = course.find('img', class_='partner-logo')['alt']\n",
    "    else:\n",
    "      provider = ''\n",
    "    url_untrim = course.a['href']\n",
    "    url = domain_url + url_untrim[:url_untrim.find('?index=product')]\n",
    "    course_name.append(name)\n",
    "    course_category.append(cat)\n",
    "    course_provider.append(provider)\n",
    "    course_url.append(url)\n",
    "    num_course += 1\n",
    "    loading_status_update_list(num_course, num_cat, 500)\n",
    "\n",
    "print(f'Scrapping course list completed! Total of {num_course} courses extracted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUTnY-WrKfxG"
   },
   "outputs": [],
   "source": [
    "# Data Matrix\n",
    "scrap_data = np.array([course_name, course_url, course_provider, course_category]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DczbBWsWKk6I",
    "outputId": "c3157afe-1b19-403a-b4d3-a8f36a12095e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3508,)\n",
      "(3508, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get Unique URL & Combine categories for the courses with multiple category labels\n",
    "\n",
    "uniq_url, uniq_url_idx = np.unique(scrap_data[:,1], return_index=True)\n",
    "uniq_data = scrap_data[uniq_url_idx, :]\n",
    "\n",
    "mul_cat = []\n",
    "\n",
    "for course in uniq_data:\n",
    "  c_url = course[1]\n",
    "  list_of_cat = scrap_data[:, 3][scrap_data[:, 1] == c_url]\n",
    "  cat_string = ''\n",
    "  for cat in list_of_cat:\n",
    "    cat_string += cat + ', '\n",
    "  cat_string = cat_string[:-2]\n",
    "  mul_cat.append(cat_string)\n",
    "\n",
    "print(np.array(mul_cat).shape)\n",
    "print(uniq_data[:,:3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwZxtYXvEqd4"
   },
   "outputs": [],
   "source": [
    "# Course List data matrix\n",
    "data = np.append(uniq_data[:,:3], np.array([mul_cat]).transpose(), axis=1)\n",
    "edx_pd = pd.DataFrame(data, columns=['Course Name', 'Course URL', 'Course Provider', 'Multi Category'])\n",
    "edx_pd.to_csv('data/webscrapping/Edx/Courses/Edx_Courses_List.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBLZdqH85DGG"
   },
   "outputs": [],
   "source": [
    "edx_course_list = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_List.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "2YHXUkET5FTd",
    "outputId": "5bc59b06-8cfe-4556-8790-6f09731ac006"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Course URL</th>\n",
       "      <th>Course Provider</th>\n",
       "      <th>Multi Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Креативное предпринимательство и проектировани...</td>\n",
       "      <td>https://www.edx.org/course/-10</td>\n",
       "      <td>ITMO University</td>\n",
       "      <td>Business &amp; Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Landscape Techniques | 山水画技法</td>\n",
       "      <td>https://www.edx.org/course/-15</td>\n",
       "      <td>Tsinghua University</td>\n",
       "      <td>Art &amp; Culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Тяжелые ионы и синтез новых элементов: совреме...</td>\n",
       "      <td>https://www.edx.org/course/-3</td>\n",
       "      <td>National Research Nuclear University</td>\n",
       "      <td>Engineering, Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Лазеры: физические основы и лазерные технологии</td>\n",
       "      <td>https://www.edx.org/course/-4</td>\n",
       "      <td>National Research Nuclear University</td>\n",
       "      <td>Engineering, Physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Особенности написания научно-технических текстов</td>\n",
       "      <td>https://www.edx.org/course/-5</td>\n",
       "      <td>National Research Nuclear University</td>\n",
       "      <td>Language, Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Учимся писать научные статьи на русском и англ...</td>\n",
       "      <td>https://www.edx.org/course/-6</td>\n",
       "      <td>National Research Nuclear University</td>\n",
       "      <td>Language, Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>المدافعون عن حقوق الإنسان</td>\n",
       "      <td>https://www.edx.org/course/-9</td>\n",
       "      <td>Amnesty International</td>\n",
       "      <td>Humanities, Law, Social Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Финансовое программирование и политика, часть ...</td>\n",
       "      <td>https://www.edx.org/course/1</td>\n",
       "      <td>The International Monetary Fund</td>\n",
       "      <td>Economics &amp; Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>스타트업 기업가정신 101: 당신의 고객은 누구입니까?</td>\n",
       "      <td>https://www.edx.org/course/101</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Business &amp; Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>创业101: 你的客户是谁？</td>\n",
       "      <td>https://www.edx.org/course/101-2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Business &amp; Management</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Course Name  ...                    Multi Category\n",
       "0  Креативное предпринимательство и проектировани...  ...             Business & Management\n",
       "1                       Landscape Techniques | 山水画技法  ...                     Art & Culture\n",
       "2  Тяжелые ионы и синтез новых элементов: совреме...  ...              Engineering, Physics\n",
       "3    Лазеры: физические основы и лазерные технологии  ...              Engineering, Physics\n",
       "4   Особенности написания научно-технических текстов  ...         Language, Social Sciences\n",
       "5  Учимся писать научные статьи на русском и англ...  ...         Language, Social Sciences\n",
       "6                          المدافعون عن حقوق الإنسان  ...  Humanities, Law, Social Sciences\n",
       "7  Финансовое программирование и политика, часть ...  ...               Economics & Finance\n",
       "8                     스타트업 기업가정신 101: 당신의 고객은 누구입니까?  ...             Business & Management\n",
       "9                                     创业101: 你的客户是谁？  ...             Business & Management\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edx_course_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FoQg012WG8Xx",
    "outputId": "f2ee169f-9d63-47a7-ab73-eac674412486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.edx.org/course/you-can-innovate-user-innovation-entrepreneurship\n",
      "https://www.edx.org/course/your-body-in-the-world-adapting-to-your-next-big-adventure\n",
      "https://www.edx.org/course/zero-energy-design-an-approach-to-make-your-buildi\n",
      "https://www.edx.org/course/zero-l-presents-introduction-to-american-civics\n",
      "https://www.edx.org/course/zoologia\n",
      "https://www.edx.org/course/zos-rexx-programming\n",
      "Scrapping course information completed!\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Load Course List of URLs\n",
    "\n",
    "edx_course_list = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_List.csv')\n",
    "title_list = np.array(edx_course_list['Course Name'])\n",
    "url_list = np.array(edx_course_list['Course URL'])\n",
    "provider_list = np.array(edx_course_list['Course Provider'])\n",
    "cat_list = np.array(edx_course_list['Multi Category'])\n",
    "\n",
    "# Extraction Individual Course Avaialable Information\n",
    "target_text = 'already enrolled!'\n",
    "\n",
    "# Element to search\n",
    "dur_div1 = 'd-flex align-items-center col-12 pb-4 pb-md-0 col-md-4'\n",
    "dur_div2 = 'h4 mb-0'\n",
    "dur_div3 = 'd-flex align-items-center col-12 pb-4 pb-md-0 col-md-6'\n",
    "mod_div1 = 'd-flex align-items-center col-12 col-md-4'\n",
    "mod_div2 = 'd-flex align-items-center col-12 col-md-6'\n",
    "cost_div1 = 'd-flex align-items-center col-12 col-md-4 pt-4 pt-md-0'\n",
    "cost_div2 = 'h4 mb-0'\n",
    "opt_cost_div1 = 'track-comparison-table-wrapper'\n",
    "sdesc_div1 = 'row no-gutters'\n",
    "sdesc_div2 = 'col-md-7 pr-4'\n",
    "sdesc_div3 = 'p'\n",
    "ldesc_div1 = 'mt-2 lead-sm html-data'\n",
    "enroll_div1 = 'enroll'\n",
    "frame_ul1 = 'mb-0 pl-3 ml-1'\n",
    "frame_ul2 = 'pl-3 ml-1 mb-0'\n",
    "instr_div1 = 'instructor-cards d-flex flex-wrap justify-content-center mx-auto justify-content-md-start'\n",
    "instr_div2 = 'instructor-cards d-flex flex-wrap justify-content-center mx-auto'\n",
    "\n",
    "# loop = int(data.shape[0] / 1000)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(loop+1):\n",
    "  # start = i*1000\n",
    "  # end = min((i+1)*1000, data.shape[0])\n",
    "\n",
    "# Initialization\n",
    "duration = []\n",
    "commitment = []\n",
    "# mode = []\n",
    "cost = []\n",
    "option = []\n",
    "short_desc = []\n",
    "long_desc = []\n",
    "num_enrol = []\n",
    "difficulty = []\n",
    "language = []\n",
    "# prerequisites = []\n",
    "video_language = []\n",
    "instructor = []\n",
    "count_course = 0\n",
    "\n",
    "start = 3500\n",
    "batch_size = 500\n",
    "end = min(start + batch_size, len(url_list))\n",
    "for url in url_list[start:end]:\n",
    "  wd.get(url)\n",
    "  time.sleep(1)\n",
    "  bs = BeautifulSoup(wd.page_source, 'html.parser')\n",
    "  print(url)\n",
    "  if bs.find('div', class_=dur_div1) is not None:\n",
    "    dur = bs.find('div', class_=dur_div1).find('div', class_=dur_div2).text.replace('Estimated ', '')\n",
    "    if bs.find('div', class_=dur_div1).div.find('div', class_='small') is not None:\n",
    "      comt = bs.find('div', class_=dur_div1).div.find('div', class_='small').text\n",
    "    else:\n",
    "      comt = ''\n",
    "  elif bs.find('div', class_=dur_div3) is not None:\n",
    "    dur = bs.find('div', class_=dur_div3).find('div', class_=dur_div2).text.replace('Estimated ', '')\n",
    "    if bs.find('div', class_=dur_div3).div.find('div', class_='small') is not None:\n",
    "      comt = bs.find('div', class_=dur_div3).div.find('div', class_='small').text\n",
    "    else:\n",
    "      comt = ''\n",
    "  else:\n",
    "    dur = ''\n",
    "    comt = ''\n",
    "\n",
    "  # if bs.find('div', class_=mod_div1) is not None:\n",
    "    # mod = bs.find('div', class_=mod_div1).div.div.text\n",
    "  # else:\n",
    "    # mod = bs.find('div', class_=mod_div2).div.div.text\n",
    "\n",
    "  if bs.find('div', class_=cost_div1) is not None:\n",
    "    cst = bs.find('div', class_=cost_div1).find('div', class_=cost_div2).text\n",
    "    if cst == 'Cost to Enroll':\n",
    "      opt = bs.find('div', class_=cost_div1).div.find('div', class_='small').text\n",
    "    else:\n",
    "      if bs.find('div', class_=opt_cost_div1) is not None:\n",
    "        opt = bs.find('div', class_=opt_cost_div1).find('p', class_='comparison-item').text\n",
    "      else:\n",
    "        opt = ''\n",
    "  else:\n",
    "    cst = 'Free'\n",
    "    opt = ''\n",
    "\n",
    "  sdesc = bs.find('div', class_=sdesc_div1).find('div', class_=sdesc_div2).find('div', class_=sdesc_div3).text\n",
    "  ldesc = bs.find('div', class_=ldesc_div1).text\n",
    "\n",
    "  session_text = bs.find('div', id=enroll_div1).find('div', class_='small')\n",
    "  if (session_text is not None) and (target_text in session_text.text):\n",
    "    enrol = session_text.text[:session_text.text.find(target_text)-1]\n",
    "  else:\n",
    "    enrol = ''\n",
    "\n",
    "  # Frame information\n",
    "  frame1 = bs.find('ul', class_=frame_ul1).find_all('li')\n",
    "  frame2 = bs.find('ul', class_=frame_ul2).find_all('li')\n",
    "  for item in frame1:\n",
    "    if 'Level: ' in item.text:\n",
    "      diff = item.text.replace('Level: ', '')\n",
    "    if 'Language: ' in item.text:\n",
    "      lange = item.text.replace('Language: ', '')\n",
    "    # if 'Prerequisites: ' in item.text:\n",
    "      # prereq = item.text.replace('Prerequisites: ', '')\n",
    "    if 'Video Transcript: ' in item.text:\n",
    "      vlang = item.text.replace('Video Transcript: ', '')\n",
    "\n",
    "  for item in frame2:\n",
    "    if 'Level: ' in item.text:\n",
    "      diff = item.text.replace('Level: ', '')\n",
    "    if 'Language: ' in item.text:\n",
    "      lang = item.text.replace('Language: ', '')\n",
    "    # if 'Prerequisites: ' in item.text:\n",
    "      # prereq = item.text.replace('Prerequisites: ', '')\n",
    "    if 'Video Transcript: ' in item.text:\n",
    "      vlang = item.text.replace('Video Transcript: ', '')\n",
    "\n",
    "  # Instructor information\n",
    "  instr_frame = bs.find('div', class_='instructor-cards d-flex flex-wrap justify-content-center mx-auto justify-content-md-start')\n",
    "  if instr_frame is not None:\n",
    "    instr_frame = instr_frame.find_all('h3')\n",
    "  else:\n",
    "    instr_frame = bs.find('div', class_='instructor-cards d-flex flex-wrap justify-content-center mx-auto').find_all('h3')\n",
    "  instr = [item.text for item in instr_frame]\n",
    "\n",
    "  # Save all information into list\n",
    "  duration.append(dur.strip())\n",
    "  commitment.append(comt.strip())\n",
    "  # mode.append(mod)\n",
    "  cost.append(cst)\n",
    "  option.append(opt)\n",
    "  short_desc.append(sdesc.strip())\n",
    "  long_desc.append(ldesc.strip())\n",
    "  num_enrol.append(enrol)\n",
    "  difficulty.append(diff.strip())\n",
    "  language.append(lang.strip())\n",
    "  # prerequisites.append(prereq)\n",
    "  video_language.append(vlang.strip())\n",
    "  instructor.append(instr)\n",
    "\n",
    "  # Update status\n",
    "  count_course += 1\n",
    "  loading_status_update_course(count_course, 500)\n",
    "\n",
    "print('Scrapping course information completed!')\n",
    "\n",
    "print(len(duration))\n",
    "print(len(commitment))\n",
    "# print(len(mode))\n",
    "print(len(cost))\n",
    "print(len(option))\n",
    "print(len(short_desc))\n",
    "print(len(long_desc))\n",
    "print(len(num_enrol))\n",
    "print(len(difficulty))\n",
    "print(len(language))\n",
    "# print(len(prerequisites))\n",
    "print(len(video_language))\n",
    "print(len(instructor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QjZnNU8bzwE",
    "outputId": "bcbfd3d0-8aa4-494c-ffaa-9c61e0b0d9f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Save batch data to file\n",
    "\n",
    "batch_data = np.array([title_list[start:end], cat_list[start:end], url_list[start:end], provider_list[start:end], short_desc, long_desc, difficulty, duration, commitment, num_enrol, cost, option, language, video_language, instructor])\n",
    "batch_pd = pd.DataFrame(batch_data.transpose(), columns=['Course Name', 'Multi Categories', 'Course URL', 'Course Provider', 'Short Description', 'Long Description', 'Difficulty', 'Duration', 'Commitment', 'Number of Enrolled', 'Cost', 'Alternative Options', 'Language', 'Video Language', 'Instructors'])\n",
    "\n",
    "filecount = int(start / batch_size)+1\n",
    "filepath = 'data/webscrapping/Edx/Courses/'\n",
    "filename = 'Edx_Courses_Data{:d}.csv'.format(filecount)\n",
    "batch_pd.to_csv(filepath+filename, index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KihLMfbvEpkd"
   },
   "outputs": [],
   "source": [
    "# Combining all parts to 1 file:\n",
    "data1 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data1.csv')\n",
    "data2 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data2.csv')\n",
    "data3 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data3.csv')\n",
    "data4 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data4.csv')\n",
    "data5 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data5.csv')\n",
    "data6 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data6.csv')\n",
    "data7 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data7.csv')\n",
    "data8 = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_Data8.csv')\n",
    "\n",
    "edx_courses = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8], axis = 0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14GCqcAjFywM"
   },
   "outputs": [],
   "source": [
    "# Save Edx course data to drive\n",
    "edx_courses.to_csv('data/webscrapping/Edx/Courses/Edx_Courses.csv', index=False, encoding='utf_8_sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KSspsqNTXNzz"
   },
   "outputs": [],
   "source": [
    "# Extract Course Image\n",
    "\n",
    "edx_course_list = pd.read_csv('data/webscrapping/Edx/Courses/Edx_Courses_List.csv')\n",
    "url_list = np.array(edx_course_list['Course URL'])\n",
    "img = []\n",
    "\n",
    "for url in url_list:\n",
    "  wd.get(url)\n",
    "  time.sleep(1)\n",
    "  bs = BeautifulSoup(wd.page_source, 'html.parser')\n",
    "\n",
    "  course_img = bs.find('div', class_='row no-gutters').find('div', class_='col-md-5 text-md-right').find('img')['src']\n",
    "  img.append(course_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "OqVzxyB_2Iqr"
   },
   "outputs": [],
   "source": [
    "df_img = pd.DataFrame(img)\n",
    "df_img.to_csv('data/webscrapping/Edx/Courses/Edx_Courses_Img.csv', index=False, encoding='utf_8_sig')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Web_Scrapping_Edx.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
